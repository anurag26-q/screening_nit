{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fb65b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.5 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.5 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.5 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.5/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 5.0/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 963.8 kB/s eta 0:00:06\n",
      "     ----------------------- --------------- 7.9/12.8 MB 769.8 kB/s eta 0:00:07\n",
      "     ----------------------- --------------- 7.9/12.8 MB 769.8 kB/s eta 0:00:07\n",
      "     ------------------------ -------------- 8.1/12.8 MB 762.6 kB/s eta 0:00:07\n",
      "     ------------------------ -------------- 8.1/12.8 MB 762.6 kB/s eta 0:00:07\n",
      "     ------------------------- ------------- 8.4/12.8 MB 757.1 kB/s eta 0:00:06\n",
      "     ------------------------- ------------- 8.4/12.8 MB 757.1 kB/s eta 0:00:06\n",
      "     --------------------------- ----------- 8.9/12.8 MB 766.8 kB/s eta 0:00:06\n",
      "     --------------------------- ----------- 9.2/12.8 MB 784.7 kB/s eta 0:00:05\n",
      "     ----------------------------- --------- 9.7/12.8 MB 809.6 kB/s eta 0:00:04\n",
      "     ----------------------------- -------- 10.0/12.8 MB 809.4 kB/s eta 0:00:04\n",
      "     ------------------------------ ------- 10.2/12.8 MB 817.3 kB/s eta 0:00:04\n",
      "     ------------------------------- ------ 10.5/12.8 MB 827.2 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.7/12.8 MB 839.9 kB/s eta 0:00:03\n",
      "     -------------------------------- ----- 11.0/12.8 MB 848.2 kB/s eta 0:00:03\n",
      "     ---------------------------------- --- 11.5/12.8 MB 864.0 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.8/12.8 MB 872.6 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 12.3/12.8 MB 896.4 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.6/12.8 MB 904.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 12.8/12.8 MB 912.3 kB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1d078",
   "metadata": {},
   "source": [
    "1. en_core_web_sm -> for the small Text\n",
    "2. en_core_web_lg -> for the large Text\n",
    "3 .en_core_web_md -> for the medium Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4048fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN nsubj\n",
      "startup VERB ccomp\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbb7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "# tokens \n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a067d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science\n",
      "the future jobs roles\n"
     ]
    }
   ],
   "source": [
    "# Text summarization\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"data science is very good for the future jobs roles\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c032e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token.text :data, token.pos_ : NOUN, token.dep_ : compound\n",
      "token.text :science, token.pos_ : NOUN, token.dep_ : nsubj\n",
      "token.text :is, token.pos_ : AUX, token.dep_ : ROOT\n",
      "token.text :very, token.pos_ : ADV, token.dep_ : advmod\n",
      "token.text :good, token.pos_ : ADJ, token.dep_ : acomp\n",
      "token.text :for, token.pos_ : ADP, token.dep_ : prep\n",
      "token.text :the, token.pos_ : DET, token.dep_ : det\n",
      "token.text :future, token.pos_ : ADJ, token.dep_ : amod\n",
      "token.text :jobs, token.pos_ : NOUN, token.dep_ : compound\n",
      "token.text :roles, token.pos_ : NOUN, token.dep_ : pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'token.text :{token.text}, token.pos_ : {token.pos_}, token.dep_ : {token.dep_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a345bb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data NOUN compound data\n",
      "science NOUN nsubj science\n",
      "is AUX ROOT be\n",
      "very ADV advmod very\n",
      "good ADJ acomp good\n",
      "for ADP prep for\n",
      "the DET det the\n",
      "future ADJ amod future\n",
      "jobs NOUN compound job\n",
      "roles NOUN pobj role\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ba8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP nsubj X.X. False False\n",
      "startup startup VERB VBD ccomp xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff0854e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text summertization \n",
    " \n",
    "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88ba825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c576cb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=list(STOP_WORDS)\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72cb8f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npl=spacy.load('en_core_web_sm')\n",
    "\n",
    "doc=nlp(text)\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95a185ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 logic \n",
    "# we need to find the token score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3178a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', '\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', '\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[4', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured']\n"
     ]
    }
   ],
   "source": [
    "tokens=[token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb3af35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'broadly': 1, 'types': 1, 'extractive': 1, 'summarization': 11, 'tasks': 1, 'depending': 2, 'program': 1, 'focuses': 2, 'generic': 3, 'obtaining': 1, 'summary': 4, 'abstract': 2, 'collection': 3, 'documents': 2, 'sets': 1, 'images': 3, 'videos': 3, 'news': 4, 'stories': 1, 'etc': 1, 'second': 1, 'query': 4, 'relevant': 2, 'called': 2, 'based': 1, 'summarizes': 1, 'objects': 1, 'specific': 1, 'Summarization': 1, 'systems': 1, 'able': 1, 'create': 1, 'text': 1, 'summaries': 2, 'machine': 1, 'generated': 1, 'user': 1, 'needs': 1, '\\n': 2, 'example': 3, 'problem': 2, 'document': 4, 'attempts': 1, 'automatically': 3, 'produce': 1, 'given': 2, 'interested': 1, 'generating': 1, 'single': 1, 'source': 2, 'use': 1, 'multiple': 1, 'cluster': 1, 'articles': 3, 'topic': 2, 'multi': 1, 'related': 2, 'application': 2, 'summarizing': 1, 'Imagine': 1, 'system': 3, 'pulls': 1, 'web': 1, 'concisely': 1, 'represents': 1, 'latest': 1, 'Image': 1, 'automatic': 1, 'consists': 1, 'selecting': 1, 'representative': 2, 'set': 2, 'larger': 1, 'images.[4': 1, 'context': 1, 'useful': 1, 'results': 1, 'image': 1, 'exploration': 1, 'Video': 1, 'domain': 1, 'creates': 1, 'trailer': 1, 'long': 1, 'video': 1, 'applications': 1, 'consumer': 1, 'personal': 1, 'want': 2, 'skip': 1, 'boring': 2, 'repetitive': 1, 'actions': 1, 'Similarly': 1, 'surveillance': 1, 'extract': 1, 'important': 1, 'suspicious': 1, 'activity': 1, 'ignoring': 1, 'redundant': 1, 'frames': 1, 'captured': 1}\n"
     ]
    }
   ],
   "source": [
    "word_freq={}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_freq.keys():\n",
    "                word_freq[word.text]=1\n",
    "            else:\n",
    "                word_freq[word.text]+=1\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a5e3e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec3fd5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the maximum score \n",
    "\n",
    "max_freq=max(word_freq.values())\n",
    "max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2744f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'broadly': 0.008264462809917356, 'types': 0.008264462809917356, 'extractive': 0.008264462809917356, 'summarization': 0.09090909090909091, 'tasks': 0.008264462809917356, 'depending': 0.01652892561983471, 'program': 0.008264462809917356, 'focuses': 0.01652892561983471, 'generic': 0.024793388429752063, 'obtaining': 0.008264462809917356, 'summary': 0.03305785123966942, 'abstract': 0.01652892561983471, 'collection': 0.024793388429752063, 'documents': 0.01652892561983471, 'sets': 0.008264462809917356, 'images': 0.024793388429752063, 'videos': 0.024793388429752063, 'news': 0.03305785123966942, 'stories': 0.008264462809917356, 'etc': 0.008264462809917356, 'second': 0.008264462809917356, 'query': 0.03305785123966942, 'relevant': 0.01652892561983471, 'called': 0.01652892561983471, 'based': 0.008264462809917356, 'summarizes': 0.008264462809917356, 'objects': 0.008264462809917356, 'specific': 0.008264462809917356, 'Summarization': 0.008264462809917356, 'systems': 0.008264462809917356, 'able': 0.008264462809917356, 'create': 0.008264462809917356, 'text': 0.008264462809917356, 'summaries': 0.01652892561983471, 'machine': 0.008264462809917356, 'generated': 0.008264462809917356, 'user': 0.008264462809917356, 'needs': 0.008264462809917356, '\\n': 0.01652892561983471, 'example': 0.024793388429752063, 'problem': 0.01652892561983471, 'document': 0.03305785123966942, 'attempts': 0.008264462809917356, 'automatically': 0.024793388429752063, 'produce': 0.008264462809917356, 'given': 0.01652892561983471, 'interested': 0.008264462809917356, 'generating': 0.008264462809917356, 'single': 0.008264462809917356, 'source': 0.01652892561983471, 'use': 0.008264462809917356, 'multiple': 0.008264462809917356, 'cluster': 0.008264462809917356, 'articles': 0.024793388429752063, 'topic': 0.01652892561983471, 'multi': 0.008264462809917356, 'related': 0.01652892561983471, 'application': 0.01652892561983471, 'summarizing': 0.008264462809917356, 'Imagine': 0.008264462809917356, 'system': 0.024793388429752063, 'pulls': 0.008264462809917356, 'web': 0.008264462809917356, 'concisely': 0.008264462809917356, 'represents': 0.008264462809917356, 'latest': 0.008264462809917356, 'Image': 0.008264462809917356, 'automatic': 0.008264462809917356, 'consists': 0.008264462809917356, 'selecting': 0.008264462809917356, 'representative': 0.01652892561983471, 'set': 0.01652892561983471, 'larger': 0.008264462809917356, 'images.[4': 0.008264462809917356, 'context': 0.008264462809917356, 'useful': 0.008264462809917356, 'results': 0.008264462809917356, 'image': 0.008264462809917356, 'exploration': 0.008264462809917356, 'Video': 0.008264462809917356, 'domain': 0.008264462809917356, 'creates': 0.008264462809917356, 'trailer': 0.008264462809917356, 'long': 0.008264462809917356, 'video': 0.008264462809917356, 'applications': 0.008264462809917356, 'consumer': 0.008264462809917356, 'personal': 0.008264462809917356, 'want': 0.01652892561983471, 'skip': 0.008264462809917356, 'boring': 0.01652892561983471, 'repetitive': 0.008264462809917356, 'actions': 0.008264462809917356, 'Similarly': 0.008264462809917356, 'surveillance': 0.008264462809917356, 'extract': 0.008264462809917356, 'important': 0.008264462809917356, 'suspicious': 0.008264462809917356, 'activity': 0.008264462809917356, 'ignoring': 0.008264462809917356, 'redundant': 0.008264462809917356, 'frames': 0.008264462809917356, 'captured': 0.008264462809917356}\n"
     ]
    }
   ],
   "source": [
    "# normaizatinhg the frequencies\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word]=word_freq[word]/max_freq\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef13a805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens=[sent for sent in doc.sents]\n",
    "sentence_tokens\n",
    "len(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bee16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 0.25619834710743805, The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 0.36363636363636354, The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 0.3553719008264462, Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      ": 0.29752066115702475, An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 0.36363636363636365, Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 0.23140495867768596, This problem is called multi-document summarization.: 0.1652892561983471, A related application is summarizing news articles.: 0.09917355371900827, Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      ": 0.2644628099173554, Image collection summarization is another application example of automatic summarization.: 0.2644628099173554, It consists in selecting a representative set of images from a larger set of images.[4]: 0.10743801652892562, A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 0.1652892561983471, Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 0.2066115702479339, This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 0.10743801652892562, Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 0.1322314049586777}\n"
     ]
    }
   ],
   "source": [
    "# sentense core \n",
    "\n",
    "sentence_score={}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_freq.keys():\n",
    "            if sent not in sentence_score.keys():\n",
    "                sentence_score[sent]=word_freq[word.text.lower()]\n",
    "            else:\n",
    "                sentence_score[sent]+=word_freq[word.text.lower()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c799ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 0.25619834710743805,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 0.36363636363636354,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 0.3553719008264462,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 0.29752066115702475,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 0.36363636363636365,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 0.23140495867768596,\n",
       " This problem is called multi-document summarization.: 0.1652892561983471,\n",
       " A related application is summarizing news articles.: 0.09917355371900827,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 0.2644628099173554,\n",
       " Image collection summarization is another application example of automatic summarization.: 0.2644628099173554,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 0.10743801652892562,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 0.1652892561983471,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 0.2066115702479339,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 0.10743801652892562,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 0.1322314049586777}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4d651e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest score of the sentence\n",
    "high_score=max(sentence_score.values())\n",
    "high_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c0350d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "select_len=int(len(sentence_tokens)*0.4)\n",
    "select_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7182c045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
       " Image collection summarization is another application example of automatic summarization.]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have to select the maximum 4 sentences out of all the sentences\n",
    "\n",
    "summary=nlargest(select_len,sentence_score,key=sentence_score.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e18c3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
       " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
       " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n',\n",
       " 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\n',\n",
       " 'Image collection summarization is another application example of automatic summarization.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary=[word.text for word in summary]\n",
    "\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f69d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871fd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ba7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
